# -*- coding: utf-8 -*-
"""Bonus_Question.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MHQzFL-sIaQkY86Euj9vitSPACMaIEa2
"""

import cv2
import json
import os
import pandas as pd
import pprint
import tensorflow as tf
import time
import cv2
import numpy as np
from tensorflow import keras
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import plot_confusion_matrix
#from mlxtend.evaluate import bias_variance_decomp

from google.colab import drive
drive.mount('/content/drive')

!unzip /content/drive/MyDrive/bollycelbfacedata.zip

# load the image
# Load an color image in grayscale
im = cv2.imread('/content/bollycelbfacedata/Aamir_Khan/1.jpg',0)
print(type(im))

resized_image = cv2.resize(im, (200, 200)) 
# show the image using MatPlotLib (seen earlier)
plt.imshow(resized_image , cmap=plt.get_cmap('gray'))
plt.show()
print(resized_image.shape)

directory = r'/content/bollycelbfacedata/'
images = []
labels = []
person = []
d=120000
for foldername in os.listdir(directory):
    #print(foldername)
    for filename in os.listdir(directory + foldername):
        #print(filename)
        ext=[".jpg",".jpeg"] 
        if filename.endswith(tuple(ext)):
            img = cv2.imread(os.path.join(directory,foldername, filename))
            if img is not None:
                resized_im = cv2.resize(img, (200, 200))
                reshape_im = np.reshape(resized_im,(d))
                images.append(reshape_im)
                labels.append(foldername)
    person.append(foldername)

data_images = np.asarray(images)
data_images.shape

labels_images = np.asarray(labels)
labels_images.shape

person

"""Pre-Processing Data

"""

from sklearn import preprocessing
data_scaled = preprocessing.scale(data_images)
print(data_scaled.shape)
data_scaled = data_images

"""Spilitting data 80:20"""

from sklearn.model_selection import train_test_split

data_train, data_test,label_train,label_test = train_test_split(data_scaled,labels_images,test_size=0.2, random_state=20)

label_train

from sklearn.preprocessing import LabelEncoder
LE = LabelEncoder()
label_train_en = LE.fit_transform(label_train)
label_test_en = LE.fit_transform(label_test)

len(data_train),len(label_train_en)

len(data_test),len(label_test)

label_test[0]

"""#Using the VGG model

"""



"""# Using the SVM model"""

from sklearn import  svm, metrics
from sklearn.metrics import accuracy_score,confusion_matrix
from sklearn.model_selection import GridSearchCV

# Create a classifier: a support vector classifier
classifier = svm.SVC(C=10,gamma=0.001,kernel='poly')
#fit to the trainin data
classifier.fit(data_train,label_train_en)

y_pred = classifier.predict(data_test)

accuracy = accuracy_score(label_test_en,y_pred)

"""**Accuracy**"""

print ("Overall Accuracy:",'{:.3%}'.format(accuracy))

!pip install deepface

import cv2
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

detector = cv2.dnn.readNetFromCaffe("/content/drive/MyDrive/res50_dai_ass2/deploy.prototxt.txt", "/content/drive/MyDrive/res50_dai_ass2/res10_300x300_ssd_iter_140000.caffemodel")

image = cv2.imread("/content/bollycelbfacedata/Aamir_Khan/1.jpg")
image = cv2.resize(image, (200, 200)) 
base_img = image.copy()

original_size = image.shape
target_size = (64, 64)
print("original image size: ", original_size)

image = cv2.resize(image, target_size)

aspect_ratio_x = (original_size[1] / target_size[1])
aspect_ratio_y = (original_size[0] / target_size[0])
print("aspect ratios x: ",aspect_ratio_x,", y: ", aspect_ratio_y)

plt.imshow(image[:,:,::-1])

imageBlob = cv2.dnn.blobFromImage(image = image)

detector.setInput(imageBlob)
detections = detector.forward()

detections[0][0].shape

detections_df = pd.DataFrame(detections[0][0]
    , columns = ["img_id", "is_face", "confidence", "left", "top", "right", "bottom"])

detections_df = detections_df[detections_df['is_face'] == 1] #0: background, 1: face

detections_df = detections_df[detections_df['confidence'] >= 0.5]

detections_df

for i, instance in detections_df.iterrows():
    #print(instance)
    
    confidence_score = str(round(100*instance["confidence"], 2))+" %"
    
    left = int(instance["left"] * 64)
    bottom = int(instance["bottom"] * 64)
    right = int(instance["right"] * 64)
    top = int(instance["top"] * 64)
        
    #low resolution
    #detected_face = image[top:bottom, left:right]
    
    #high resolution
    detected_face = base_img[int(top*aspect_ratio_y):int(bottom*aspect_ratio_y), int(left*aspect_ratio_x):int(right*aspect_ratio_x)]
    
    if detected_face.shape[0] > 0 and detected_face.shape[1] > 0:
        
        print("Id ",i)
        print("Confidence: ", confidence_score)
        #detected_face = cv2.resize(detected_face, (224, 224))
        plt.imshow(detected_face[:,:,::-1])
        plt.axis('off')
        plt.show()

plt.figure(figsize = (20, 20))
#tmp_img = image.copy()
#tmp_img = cv2.resize(tmp_img, (600, 600))
plt.imshow(base_img[:,:,::-1])
plt.axis('off')
plt.show()

img_1 = base_img.copy()

img_1[int(top*aspect_ratio_y)+10:int(bottom*aspect_ratio_y)-60,int(left*aspect_ratio_x):int(right*aspect_ratio_x)] = 0

plt.imshow(img_1)

test_im = np.reshape(img_1,(1,d)) 
org_img = np.reshape(base_img,(1,d))

person[classifier.predict(org_img)[0]]

person[classifier.predict(test_im)[0]]

